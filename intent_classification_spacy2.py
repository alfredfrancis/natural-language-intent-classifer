# -*- coding: utf-8 -*-
"""intent_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hN0HOR4bOQLV8b4igjEpMaUTSlrSHfM8
"""

# !pip install -q -U tensorflow==1.8.0
# !pip install -q -U sklearn
# !pip install -q -U  numpy
# !pip install -q -U spacy
# !python -m spacy download en

import numpy as np
np.random.seed(1)



import numpy as np
import tensorflow as tf
import spacy
nlp = spacy.load('en')

#training data

X =[u'i want to cancel', u'cancel that', u'cancel', u'im looking for a place in banglore serving Chinese', u"i'm looking for Chinese food", u"I'm looking for south indian places", u'im looking for a place near banglore', u"i'm looking for a place to eat near down town la", u"i'm looking for a place in new york", u'im looking for a place in banglore', u'looking for indian cuisine in new york', u'central indian restaurant', u'I am looking for mexican indian fusion', u'I am looking a restaurant in 29432', u'I am looking for asian fusion food', u'anywhere near 18328', u'anywhere in the west', u'search for restaurants', u'i am looking for an indian spot called olaolaolaolaolaola', u'show me a mexican place in the centre', u'show me chines restaurants in the north', u'show me chinese restaurants', u"i'm looking for a place in the north of town", u'I am searching for a dinner spot', u'I want to grab lunch', u"i'm looking for a place to eat", u'dear sir', u'good evening\n', u'good morning\n', u'hi\n', u'hello\n', u'hey there\n', u'howdy\n', u'hey', u'sounds really good', u'great choice\n', u'correct\n', u'right, thank you\n', u'great\n', u'ok\n', u"that's right\n", u'indeed\n', u'yeah\n', u'yep\n', u'yes\n', u'have a good one', u'Bye bye\n', u'farewell\n', u'end\n', u'stop\n', u'good bye\n', u'goodbye\n', u'bye', u'thank you iky', u'thanks', u'thank you very much']
y = ['cancel', 'cancel', 'cancel', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'restaurant_search', 'greet', 'greet', 'greet', 'greet', 'greet', 'greet', 'greet', 'greet', 'affirm', 'affirm', 'affirm', 'affirm', 'affirm', 'affirm', 'affirm', 'affirm', 'affirm', 'affirm', 'affirm', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'goodbye', 'thank_you', 'thank_you', 'thank_you']

vocab_size = 384

nlp = spacy.load('en')
nlp.add_pipe(nlp.create_pipe('sentencizer'))

x_train = list(nlp.pipe(X))

def get_features(docs, max_length):
    docs = list(docs)
    Xs = np.zeros((len(docs), max_length), dtype='int32')
    for i, doc in enumerate(docs):
        j = 0
        for token in doc:
            vector_id = token.vocab.vectors.find(key=token.orth)
            if vector_id >= 0:
                Xs[i, j] = vector_id
            else:
                Xs[i, j] = 0
            j += 1
            if j >= max_length:
                break
    return Xs

train_X = get_features(x_train, 384)

print(train_X[20])

num_labels = len(set(y))
print(num_labels)
from sklearn.preprocessing import LabelBinarizer
encoder = LabelBinarizer()
encoder.fit(y)
y_train = encoder.transform(y)

model = tf.keras.Sequential()
model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(vocab_size,)))
model.add(tf.keras.layers.Dropout(0.15))
model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))
model.add(tf.keras.layers.Dropout(0.15))
model.add(tf.keras.layers.Dense(num_labels, activation=tf.nn.softmax))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy',"categorical_crossentropy"])

model.summary()

model.fit(x_train, y_train,shuffle=True, epochs=50, verbose=1)

query = "im"

# x_predict = tokenize.texts_to_matrix([query])

x_predict = [nlp(unicode(query))]

prediction = model.predict(np.array([x_predict[0]]))
print(prediction)
text_labels = encoder.classes_ 
predicted_label = text_labels[np.argmax(prediction[0])]
print("Predicted label: " + predicted_label )

print("Confidence: %.2f"% prediction[0].max())

loss, accuracy = model.evaluate(x_train, y_train)
print('Test accuracy: %.2f' % (accuracy))